

<!DOCTYPE html>
<html lang="en">
<head>
    
    <!-- Required meta tags -->
    <meta charset="utf-8"/>
    <meta name="image" property="og:image" content="static/images/PaRiS.png">
    <meta name="title" property="og:title" content="Workshop on Personalization and Recommendations in Search (PaRiS)">
    <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <!-- External Javascript libs_ext  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script
            src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"
    ></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
            integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js"
            integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
            crossorigin="anonymous"></script>


    <!-- Library libs_ext -->
    <script src="static/js/libs_ext/typeahead.bundle.js"></script>


    <!--    Internal Libs -->
    <script src="static/js/data/api.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
          integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY="
          crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
            href="static/css/Lato.css"
            rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet"/>
    <link
            href="static/css/Cuprum.css"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="static/css/main.css"/>
<!--    <link rel="stylesheet" href="static/css/fa_regular.css"/>-->
    <link rel="stylesheet" href="static/css/fa_solid.css"/>
    <link rel="stylesheet" href="static/css/lazy_load.css"/>
    <link rel="stylesheet" href="static/css/typeahead.css"/>

    <title>PaRiS 2024: Keynotes</title>
    
</head>

<body>
<!-- NAV -->

<nav
        class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto"
        id="main-nav"
>
    <div class="container">
        <a class="navbar-brand" href="index.html">
            <img
                    class="logo" src="static/images/PaRiS.png"
                    height="auto"
            width="180px"
            />
        </a>
        
        <button
                class="navbar-toggler"
                type="button"
                data-toggle="collapse"
                data-target="#navbarNav"
                aria-controls="navbarNav"
                aria-expanded="false"
                aria-label="Toggle navigation"
        >
            <span class="navbar-toggler-icon"></span>
        </button>
        <div
                class="collapse navbar-collapse text-right flex-grow-1"
                id="navbarNav"
        >
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="index.html">Home</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="dates.html">Dates</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="schedule.html">Schedule</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="submissions.html">Submissions</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="keynotes.html">Keynotes</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="previous.html">Previous Years</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>



<!-- User Overrides -->
 

<div class="container">
    <!-- Tabs -->
    <div class="tabs">
         
    </div>
    <!-- Content -->
    <div class="content">
        

<!-- Speakers -->
<div class="border-top my-3"></div>
<div class="row p-4" id="faq">
  <div class="col-12 bd-content">
    <h2 class="text-center">Speakers</h2>
  </div>
</div>
<div class="speakers">
  
<div class="row p-4">
  <div class="col-md-12">
    <div class="card">
      <div class="card-header">
        <div class="row">
          <div class="col-md-2 col-sm-5">
            <img src="static/images/speakers/Alane_headshot.jpg" width="100%" class="img-thumbnail" />
          </div>
          <div class="col-md-10 col-sm-6">
            <div class="m-3 text-muted">
              <h3>
                <a href="speaker_1.html" class="main-title">
                   Interactive Language Agents: Training, Evaluation, and Interface
                </a>
              </h3>
            </div>
            <div class="m-3 text-muted">
              <span class="card-title h3">
                Alane Suhr  /  UC Berkeley
              </span>
            </div>
            <p></p>
            <div class="m-3">
              The increasing capability of LLMs makes them appealing for adoption in labor-intensive human tasks. For example, significant efforts have recently focused on developing agents -- systems that map observations and instructions to executable actions -- and their benchmarks in real-world tasks like web navigation. In this talk, I will discuss recent work in training and improving such models through interactions with human users, and developing better evaluations for these agents, which in turn can be used to automatically improve agent performance without requiring any demonstration data or human annotation. However, in developing systems like this, and in applying LLMs and other large pre-trained models to real-world problems, we should be aware of their fundamental limitations; for example, their sensitivity to design considerations like prompt formatting. I will detail recent work where we find that LLMs can be incredibly sensitive to arbitrary design decisions, like choices of separators or multiple choice labels.
            </div>
            <div class="m-3">
              <b>Speaker Bio:</b> Alane Suhr recently joined EECS and BAIR at UC Berkeley as an Assistant Professor. Alane's work focuses on building language-using systems that communicate with and learn from human users in collaborative, situated interactions. Prior to joining Berkeley, Alane completed a PhD in Computer Science at Cornell University / Cornell Tech and spent a year afterwards as a Young Investigator at the Allen Institute for AI.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="row p-4">
  <div class="col-md-12">
    <div class="card">
      <div class="card-header">
        <div class="row">
          <div class="col-md-2 col-sm-5">
            <img src="static/images/speakers/Anne_headshot.png" width="100%" class="img-thumbnail" />
          </div>
          <div class="col-md-10 col-sm-6">
            <div class="m-3 text-muted">
              <h3>
                <a href="speaker_2.html" class="main-title">
                  More Like This…how? Combining engagement and semantic signals for recommending similar titles at Netflix
                </a>
              </h3>
            </div>
            <div class="m-3 text-muted">
              <span class="card-title h3">
                Anne Cocos  /  Netflix
              </span>
            </div>
            <p></p>
            <div class="m-3">
              Quantifying similarity between entities to be ranked (e.g. movie titles) is a core capability of recommendation systems. The meaning of similarity can take several forms. Many systems rely on an engagement-based measure of similarity calculated via collaborative filtering -- if users co-engage with a pair of entities frequently enough, their embeddings should be similar. But leaning on co-engagement similarity alone can degrade system performance in recommending new or unpopular entities for which engagement data is scarce. In this talk I will present our work on SemanticGNN, a graph-based model which integrates semantic factors like genre, maturity level, and themes to enhance similarity measurements. SemanticGNN addresses challenges of relation imbalance and scaling that are common in training graph-based models for real world use cases. Our approach uses a relation-aware attention graph neural network (GNN) to balance diverse relation types in our graph. Additionally we develop a task-specific graph partitioning scheme to scale training to millions of nodes and billions of edges on multiple GPUs. Deployed within Netflix, this model has shown up to 35% improved performance on similarity judgment tasks.

            </div>
            <div class="m-3">
              <b>Speaker Bio:</b> Anne Cocos is an applied machine learning research scientist who has built ML-powered products and teams across multiple domains. She is currently a Senior Research Scientist at Netflix where she develops algorithms for Netflix search and recommendation systems. In previous roles she has led machine learning at an early-stage geospatial data startup, overseen the development of GlaxoSmithKline's biomedical knowledge graph for drug discovery, and run pediatric biomedical research projects at The Children's Hospital of Philadelphia. Anne completed her PhD in computer science at the University of Pennsylvania, where she was supported by the Google Ph.D. Fellowship and the AI2 Key Scientific Challenges award. Before focusing on artificial intelligence, Anne served as an intelligence officer in the U.S. Navy.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="row p-4">
  <div class="col-md-12">
    <div class="card">
      <div class="card-header">
        <div class="row">
          <div class="col-md-2 col-sm-5">
            <img src="static/images/speakers/Michael_headshot.png" width="100%" class="img-thumbnail" />
          </div>
          <div class="col-md-10 col-sm-6">
            <div class="m-3 text-muted">
              <h3>
                <a href="speaker_3.html" class="main-title">
                  Personalized Generation: Research Challenges & Opportunities
                </a>
              </h3>
            </div>
            <div class="m-3 text-muted">
              <span class="card-title h3">
                Michael Bendersky  /  Google DeepMind
              </span>
            </div>
            <p></p>
            <div class="m-3">
              Generating content that is adapted to personal style and context is an emerging research area that has been steadily gaining attention from the research community. In this talk, I will review some of our ongoing work on improving the capabilities of large language models (LLMs) to generate personalized content. I will first introduce the general framework for personalized generation, and then delve deeper into how LLMs can be more effectively aligned with personal context. Finally, I will discuss the evaluation challenges inherent in personalized generation systems, and propose potential solutions to these challenges.
            </div>
            <div class="m-3">
              <b>Speaker Bio:</b> Michael Bendersky is an Engineering Director at Google DeepMind. He is currently managing a team whose mission is improving algorithms, models, and metrics for information discovery across Google products. Michael holds a Ph.D. from the University of Massachusetts Amherst, and is a Distinguished Member of the ACM. Michael co-authored over 100 publications in the areas of information retrieval, natural language processing, machine learning, and artificial intelligence. He co-authored two books in the 'Foundations and Trends in Information Retrieval' series: 'Information Retrieval with Verbose Queries', and 'Search and Discovery in Personal Email Collections'
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="row p-4">
  <div class="col-md-12">
    <div class="card">
      <div class="card-header">
        <div class="row">
          <div class="col-md-2 col-sm-5">
            <img src="static/images/speakers/neginrahimi.jpeg" width="100%" class="img-thumbnail" />
          </div>
          <div class="col-md-10 col-sm-6">
            <div class="m-3 text-muted">
              <h3>
                <a href="speaker_4.html" class="main-title">
                  Toward Interpretable Information Access Systems
                </a>
              </h3>
            </div>
            <div class="m-3 text-muted">
              <span class="card-title h3">
                Negin Rahimi  /  University of Massachusetts Amherst
              </span>
            </div>
            <p></p>
            <div class="m-3">
              Information access systems provide substantial information to many human activities and decision making with different levels of sensitivity. Existing information seeking systems, including those that employ large language models (LLMs), face challenges in appropriately providing users with unbiased, diverse, and well-explained responses to explore the answer space.
 In this talk, I will present a summary of our works on interpretable information retrieval. I will provide a more detailed description of our efforts to enhance the intrinsic interpretability of models for providing users with diverse and unbiased results. Through enhanced interpretability, we have achieved comparable or even higher effectiveness. I conclude by highlighting the mutual benefits between interpretable information retrieval and generative AI systems.
            </div>
            <div class="m-3">
              <b>Speaker Bio:</b> Negin Rahimi is an Assistant Professor in UMass Amherst's Manning College of Information and Computer Sciences, where she is part of the Center for Intelligent Information Retrieval. Her research aims to build interactive and unbiased intelligent systems for information access through learning, user interaction, and enhanced interpretability. Her research is supported by Google Research Scholar, Adobe, and NSF awards including NSF CAREER award.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="row p-4">
  <div class="col-md-12">
    <div class="card">
      <div class="card-header">
        <div class="row">
          <div class="col-md-2 col-sm-5">
            <img src="static/images/speakers/surya-teja-kallumadi-featured-800x800.jpeg" width="100%" class="img-thumbnail" />
          </div>
          <div class="col-md-10 col-sm-6">
            <div class="m-3 text-muted">
              <h3>
                <a href="speaker_5.html" class="main-title">
                  Task aware personalization in eCommerce search and recommendations
                </a>
              </h3>
            </div>
            <div class="m-3 text-muted">
              <span class="card-title h3">
                Surya Kallumadi  /  Lowe&#39;s
              </span>
            </div>
            <p></p>
            <div class="m-3">
              Talk Abstract TBD
            </div>
            <div class="m-3">
              <b>Speaker Bio:</b> Surya Kallumadi is a director of applied science at Lowe's, where he leads the machine learning initiatives in core search, recommendations, and personalization. Prior to that, he was with the Search Science team at The Home Depot, leading the search ranking initiative. In the past he worked with the data science teams at Flipkart and eBay in the fields of search and query understanding.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="row p-4">
  <div class="col-md-12">
    <div class="card">
      <div class="card-header">
        <div class="row">
          <div class="col-md-2 col-sm-5">
            <img src="image" width="100%" class="img-thumbnail" />
          </div>
          <div class="col-md-10 col-sm-6">
            <div class="m-3 text-muted">
              <h3>
                <a href="speaker_6.html" class="main-title">
                  Improving Relevance and Product Discoverability in Grocery search results
                </a>
              </h3>
            </div>
            <div class="m-3 text-muted">
              <span class="card-title h3">
                Tejaswi Tenneti  /  Instacart
              </span>
            </div>
            <p></p>
            <div class="m-3">
              In this presentation, we delve into two innovative approaches designed to improve grocery search results by enhancing both relevance and discoverability. Our focus is on the development and application of a new product relevance classification model, alongside the strategic integration of LLMs to improve discoverability of novel products.
                                                                                                                                Enhancing Search Relevance via ESCI Classification model:
                                                                                                                                We use the ESCI classification model, which classifies the relationship between user queries and catalog products into seven clear groups: Exact Match, Strong Substitute, Weak Substitute, Close Complement, Remote Complement, Irrelevant, and Offensive. This model helps us handle search results better by allowing for more specific retrieval and smarter ranking strategies. It simplifies the way we show search results, clearly highlighting exact matches and strategically displaying the substitutes and complements to create a better shopping experience for users.
                                                                                                                                Improving Product Discoverability with LLMs:
                                                                                                                                To tackle the limitations of our previous Query Understanding (QU) models, particularly the challenges with sparse data for tail and non-grocery queries, we integrated Large Language Models into our search framework. LLMs have significantly advanced our capability to interpret queries and content, generating inspirational content that not only enriches the search results page but also drives conversions through enhanced relevance and user engagement.
                                                                                                                                Conclusion:
                                                                                                                                By leveraging the precise categorization capabilities of the ESCI model and the contextual understanding provided by LLMs, we were able to anticipate and meet consumer needs more effectively. This has led to improved engagement and incremental revenue.
            </div>
            <div class="m-3">
              <b>Speaker Bio:</b> Bio
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

</div>


    </div>
</div>



<!-- Google Analytics -->
<script
        async
        src="https://www.googletagmanager.com/gtag/js?id=UA-"
></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag("js", new Date());
  gtag("config", "UA-");
</script>

<!-- Footer -->
<footer class="footer bg-light p-4">
    <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2024 PaRis Organization Committee</p>
    </div>
</footer>

<!-- Code for hash tags -->
<script type="text/javascript">
  $(document).ready(function () {
    if (window.location.hash !== "") {
      $(`a[href="${window.location.hash}"]`).tab("show");
    }

    $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
      const hash = $(e.target).attr("href");
      if (hash.substr(0, 1) === "#") {
        const position = $(window).scrollTop();
        window.location.replace(`#${hash.substr(1)}`);
        $(window).scrollTop(position);
      }
    });
  });
</script>
<!--    <script src="static/js/modules/lazyLoad.js"></script>-->

</body>
</html>